{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97bdd0ba",
   "metadata": {},
   "source": [
    "TASK ONE: TEXT CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d9808b",
   "metadata": {},
   "source": [
    "1. Download the BBC dataset provided on Moodle. The dataset, created by [Greene and Cunningham, 2006],\n",
    "is a collection of 2225 documents from the BBC news website already categorized into 5 classes: business,\n",
    "entertainment, politics, sport, and tech.\n",
    "\n",
    "2. Plot the distribution of the instances in each class and save the graphic in a file called BBC-distribution.pdf.\n",
    "You may want to use matplotlib . pyplot and savefig to do this. This pre-analysis of the data set will\n",
    "allow you to determine if the classes are balanced, and which metric is more appropriate to use to evaluate\n",
    "the performance of your classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3419d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets as ds\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3304fbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ds.load_files(\"BBC-20210914T194535Z-001\\\\BBC\", encoding = \"latin1\")\n",
    "distribution = Counter(data['target'])\n",
    "for target_name in data['target_names']:\n",
    "    distribution[target_name] = distribution.pop(data['target_names'].index(target_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e2e0a81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(distribution.keys(), distribution.values())\n",
    "plt.savefig(\"BBC-distribution.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1702a8c3",
   "metadata": {},
   "source": [
    "3. Load the corpus using load_files and make sure you set the encoding to latin1. This will read the file\n",
    "structure and assign the category name to each file from their parent directory name.\n",
    "4. Pre-process the dataset to have the features ready to be used by a multinomial Naive Bayes classifier. This\n",
    "means that the frequency of each word in each class must be computed and stored in a term-document\n",
    "matrix. For this, you can use feature_extraction.text.CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ae601ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "825d895d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data.data, data.target\n",
    "vectorizer = CountVectorizer()\n",
    "td_matrix = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8019ae82",
   "metadata": {},
   "source": [
    "5. Split the dataset into 80% for training and 20% for testing. For this, you must use train test split with\n",
    "the parameter random state set to None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc94da43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c46cd907",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(td_matrix, y, test_size=0.2, random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8133eb28",
   "metadata": {},
   "source": [
    "6. Train a multinomial Naive Bayes Classifier (naive_bayes.MultinomialNB) on the training set using the\n",
    "default parameters and evaluate it on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "564a3a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33800c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9f559e",
   "metadata": {},
   "source": [
    "7. In a file called bbc-performance . txt , save the following information: (to make it easier for theTAs, make\n",
    "sure that your output for each sub-question below is clearly marked in your output file, using the headings\n",
    "(a), (b) ... )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2edbc0",
   "metadata": {},
   "source": [
    "&emsp;(a) a clear separator (a sequence of hyphens or stars) and string clearly describing the model (e.g. \"MultinomialNB default values, try 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "126359bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"bbc-performance.txt\", \"w+\") as f:\n",
    "    f.write(\"*******************************************************\\n\")\n",
    "    f.write(\"********* MULTINOMIALNB DEFAULT VALUES, TRY 1 *********\\n\")\n",
    "    f.write(\"*******************************************************\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784ea2cd",
   "metadata": {},
   "source": [
    "&emsp;(b) the confusion matrix (you can use confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d815c720",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37e25c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"b) confusion matrix\\n\")\n",
    "    f.write(np.array2string(conf_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c16c7f7",
   "metadata": {},
   "source": [
    "&emsp;(c) the precision, recall, and F1-measure for each class (you can use classification_report) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72f1cfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3709d0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cla_report = classification_report(y_test, y_pred, target_names = data.target_names)\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"\\n\\nc) classification report\\n\")\n",
    "    f.write(cla_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067950d5",
   "metadata": {},
   "source": [
    "&emsp;(d) the accuracy, macro-average F1 and weighted-average F1 of the model (you can use accuracy_score and f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d297434",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c1b9417",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "macro_f1 = f1_score(y_test, y_pred, average = 'macro')\n",
    "weighted_f1 = f1_score(y_test, y_pred, average = 'weighted')\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"\\n\\nd) accuracy and f1 scores\\n\")\n",
    "    f.write(\"accuracy: \" + str(acc_score) + \"\\n\")\n",
    "    f.write(\"macro f1 score: \" + str(macro_f1) + \"\\n\")\n",
    "    f.write(\"weighted f1 score: \" + str(weighted_f1) + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6e1ff3",
   "metadata": {},
   "source": [
    "&emsp;(e) the prior probability of each class  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d0ed01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = sum(distribution.values())\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"e) prior probabilities\\n\")\n",
    "    for key, value in distribution.items():\n",
    "        f.write(key + \": \" + str(value/total) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc03213",
   "metadata": {},
   "source": [
    "&emsp;(f) the size of the vocabulary (i.e. the number of different words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "482bbef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_of_vocabulary = td_matrix.shape[1]\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"\\nf) size of the vocabulary\\n\")\n",
    "    f.write(str(size_of_vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0fa193",
   "metadata": {},
   "source": [
    "&emsp;(g) the number of word-tokens in each class (i.e. the number of words in total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "446e4d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {}\n",
    "for doc, category in zip(td_matrix, y):\n",
    "    if(category in categories.keys()):\n",
    "        categories[category] = categories[category] + np.sum(doc)\n",
    "    else:\n",
    "        categories[category] = np.sum(doc)\n",
    "\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"\\n\\ng) number of word-tokens in each class\\n\")\n",
    "    for key, value in categories.items():\n",
    "        f.write(data.target_names[key] + \": \" + str(value)+ \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e869d4d",
   "metadata": {},
   "source": [
    "&emsp;(h) the number of word-tokens in the entire corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b674d7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_wordTokens = np.sum(td_matrix)\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"\\nh) number of word-tokens in the entire corpus\\n\")\n",
    "    f.write(str(number_of_wordTokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f123c5",
   "metadata": {},
   "source": [
    "&emsp;(i) the number and percentage of words with a frequency of zero in each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "786d16f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {}\n",
    "for doc, category in zip(td_matrix, y):\n",
    "    if(category in categories.keys()):\n",
    "        categories[category] = categories[category] + doc\n",
    "    else:\n",
    "        categories[category] = doc\n",
    "\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"\\n\\ni) the number and percentage of words with a frequency of zero in each class\\n\")\n",
    "    for key, value in categories.items():\n",
    "        vocabulary_with_frequency0 = size_of_vocabulary - value.count_nonzero()\n",
    "        f.write(data.target_names[key] + \": \" + str(vocabulary_with_frequency0) + \"(\" + str(vocabulary_with_frequency0/size_of_vocabulary*100) + \"%)\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab163a9",
   "metadata": {},
   "source": [
    "&emsp;(j) the number and percentage of words with a frequency of one in the entire corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b02f51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = vectorizer.get_feature_names()\n",
    "count_list = np.asarray(td_matrix.sum(axis=0))[0]\n",
    "word_count_dict = dict(zip(word_list, count_list))\n",
    "words_with_frequency1 = sum(value == 1 for value in word_count_dict.values())\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"\\nj) the number and percentage of words with a frequency of one in the entire corpus\\n\")\n",
    "    f.write(\"number: \" + str(words_with_frequency1) + \"\\n\")\n",
    "    f.write(\"percentage: \" + str(words_with_frequency1/len(vectorizer.vocabulary_)*100) + \"%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eadb1b4",
   "metadata": {},
   "source": [
    "&emsp;(k) your 2 favorite words (that are present in the vocabulary) and their log-prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95bce97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "110544e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "word1 = \"hope\"\n",
    "word2 = \"peace\"\n",
    "log_prob_word1 = math.log(word_count_dict[\"hope\"]/number_of_wordTokens)\n",
    "log_prob_word2 = math.log(word_count_dict[\"peace\"]/number_of_wordTokens)\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"\\nk) your 2 favorite words (that are present in the vocabulary) and their log-prob\\n\")\n",
    "    f.write(word1 + \": \" + str(log_prob_word1) + \"\\n\")\n",
    "    f.write(word2 + \": \" + str(log_prob_word2) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79764b0a",
   "metadata": {},
   "source": [
    "&emsp;8. Redo steps 6 and 7 without changing anything (do not redo step 5, the dataset split). Change t he\n",
    "model name to something like \"MultinomialNB default values, try 2\" and append the results to the file\n",
    "bbc-performance.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2df9a40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"*******************************************************\\n\")\n",
    "    f.write(\"********* MULTINOMIALNB DEFAULT VALUES, TRY 2 *********\\n\")\n",
    "    f.write(\"*******************************************************\\n\\n\")\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"b) confusion matrix\\n\")\n",
    "    f.write(np.array2string(conf_matrix))\n",
    "cla_report = classification_report(y_test, y_pred, target_names = data.target_names)\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"\\n\\nc) classification report\\n\")\n",
    "    f.write(cla_report)\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "macro_f1 = f1_score(y_test, y_pred, average = 'macro')\n",
    "weighted_f1 = f1_score(y_test, y_pred, average = 'weighted')\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"\\n\\nd) accuracy and f1 scores\\n\")\n",
    "    f.write(\"accuracy: \" + str(acc_score) + \"\\n\")\n",
    "    f.write(\"macro f1 score: \" + str(macro_f1) + \"\\n\")\n",
    "    f.write(\"weighted f1 score: \" + str(weighted_f1) + \"\\n\\n\")\n",
    "total = sum(distribution.values())\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"e) prior probabilities\\n\")\n",
    "    for key, value in distribution.items():\n",
    "        f.write(key + \": \" + str(value/total) + \"\\n\")\n",
    "size_of_vocabulary = td_matrix.shape[1]\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"\\nf) size of the vocabulary\\n\")\n",
    "    f.write(str(size_of_vocabulary))\n",
    "categories = {}\n",
    "for doc, category in zip(td_matrix, y):\n",
    "    if(category in categories.keys()):\n",
    "        categories[category] = categories[category] + np.sum(doc)\n",
    "    else:\n",
    "        categories[category] = np.sum(doc)\n",
    "\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"\\n\\ng) number of word-tokens in each class\\n\")\n",
    "    for key, value in categories.items():\n",
    "        f.write(data.target_names[key] + \": \" + str(value)+ \"\\n\")\n",
    "number_of_wordTokens = np.sum(td_matrix)\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"\\nh) number of word-tokens in the entire corpus\\n\")\n",
    "    f.write(str(number_of_wordTokens))\n",
    "categories = {}\n",
    "for doc, category in zip(td_matrix, y):\n",
    "    if(category in categories.keys()):\n",
    "        categories[category] = categories[category] + doc\n",
    "    else:\n",
    "        categories[category] = doc\n",
    "\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"\\n\\ni) the number and percentage of words with a frequency of zero in each class\\n\")\n",
    "    for key, value in categories.items():\n",
    "        vocabulary_with_frequency0 = size_of_vocabulary - value.count_nonzero()\n",
    "        f.write(data.target_names[key] + \": \" + str(vocabulary_with_frequency0) + \"(\" + str(vocabulary_with_frequency0/size_of_vocabulary*100) + \"%)\\n\")\n",
    "word_list = vectorizer.get_feature_names()\n",
    "count_list = np.asarray(td_matrix.sum(axis=0))[0]\n",
    "word_count_dict = dict(zip(word_list, count_list))\n",
    "words_with_frequency1 = sum(value == 1 for value in word_count_dict.values())\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"\\nj) the number and percentage of words with a frequency of one in the entire corpus\\n\")\n",
    "    f.write(\"number: \" + str(words_with_frequency1) + \"\\n\")\n",
    "    f.write(\"percentage: \" + str(words_with_frequency1/len(vectorizer.vocabulary_)*100) + \"%\\n\")\n",
    "word1 = \"hope\"\n",
    "word2 = \"peace\"\n",
    "log_prob_word1 = math.log(word_count_dict[\"hope\"]/number_of_wordTokens)\n",
    "log_prob_word2 = math.log(word_count_dict[\"peace\"]/number_of_wordTokens)\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"\\nk) your 2 favorite words (that are present in the vocabulary) and their log-prob\\n\")\n",
    "    f.write(word1 + \": \" + str(log_prob_word1) + \"\\n\")\n",
    "    f.write(word2 + \": \" + str(log_prob_word2) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66c51c4",
   "metadata": {},
   "source": [
    "&emsp;9. Redo steps 6 and 7 again, but this time, change the smoothing value to 0 . 0001. Append the results at the\n",
    "end of bbc-performance . txt ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90e88fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB(alpha = 0.0001)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"*******************************************************\\n\")\n",
    "    f.write(\"********* MULTINOMIALNB WITH 0.0001 SMOOTHING *********\\n\")\n",
    "    f.write(\"*******************************************************\\n\\n\")\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"b) confusion matrix\\n\")\n",
    "    f.write(np.array2string(conf_matrix))\n",
    "cla_report = classification_report(y_test, y_pred, target_names = data.target_names)\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"\\n\\nc) classification report\\n\")\n",
    "    f.write(cla_report)\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "macro_f1 = f1_score(y_test, y_pred, average = 'macro')\n",
    "weighted_f1 = f1_score(y_test, y_pred, average = 'weighted')\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"\\n\\nd) accuracy and f1 scores\\n\")\n",
    "    f.write(\"accuracy: \" + str(acc_score) + \"\\n\")\n",
    "    f.write(\"macro f1 score: \" + str(macro_f1) + \"\\n\")\n",
    "    f.write(\"weighted f1 score: \" + str(weighted_f1) + \"\\n\\n\")\n",
    "total = sum(distribution.values())\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"e) prior probabilities\\n\")\n",
    "    for key, value in distribution.items():\n",
    "        f.write(key + \": \" + str(value/total) + \"\\n\")\n",
    "size_of_vocabulary = td_matrix.shape[1]\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"\\nf) size of the vocabulary\\n\")\n",
    "    f.write(str(size_of_vocabulary))\n",
    "categories = {}\n",
    "for doc, category in zip(td_matrix, y):\n",
    "    if(category in categories.keys()):\n",
    "        categories[category] = categories[category] + np.sum(doc)\n",
    "    else:\n",
    "        categories[category] = np.sum(doc)\n",
    "\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"\\n\\ng) number of word-tokens in each class\\n\")\n",
    "    for key, value in categories.items():\n",
    "        f.write(data.target_names[key] + \": \" + str(value)+ \"\\n\")\n",
    "number_of_wordTokens = np.sum(td_matrix)\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"\\nh) number of word-tokens in the entire corpus\\n\")\n",
    "    f.write(str(number_of_wordTokens))\n",
    "categories = {}\n",
    "for doc, category in zip(td_matrix, y):\n",
    "    if(category in categories.keys()):\n",
    "        categories[category] = categories[category] + doc\n",
    "    else:\n",
    "        categories[category] = doc\n",
    "\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"\\n\\ni) the number and percentage of words with a frequency of zero in each class\\n\")\n",
    "    for key, value in categories.items():\n",
    "        vocabulary_with_frequency0 = size_of_vocabulary - value.count_nonzero()\n",
    "        f.write(data.target_names[key] + \": \" + str(vocabulary_with_frequency0) + \"(\" + str(vocabulary_with_frequency0/size_of_vocabulary*100) + \"%)\\n\")\n",
    "word_list = vectorizer.get_feature_names()\n",
    "count_list = np.asarray(td_matrix.sum(axis=0))[0]\n",
    "word_count_dict = dict(zip(word_list, count_list))\n",
    "words_with_frequency1 = sum(value == 1 for value in word_count_dict.values())\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"\\nj) the number and percentage of words with a frequency of one in the entire corpus\\n\")\n",
    "    f.write(\"number: \" + str(words_with_frequency1) + \"\\n\")\n",
    "    f.write(\"percentage: \" + str(words_with_frequency1/len(vectorizer.vocabulary_)*100) + \"%\\n\")\n",
    "word1 = \"hope\"\n",
    "word2 = \"peace\"\n",
    "log_prob_word1 = math.log(word_count_dict[\"hope\"]/number_of_wordTokens)\n",
    "log_prob_word2 = math.log(word_count_dict[\"peace\"]/number_of_wordTokens)\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"\\nk) your 2 favorite words (that are present in the vocabulary) and their log-prob\\n\")\n",
    "    f.write(word1 + \": \" + str(log_prob_word1) + \"\\n\")\n",
    "    f.write(word2 + \": \" + str(log_prob_word2) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43c647d",
   "metadata": {},
   "source": [
    "&emsp;10. Redo steps 6 and 7, but this time, change the smoothing value to 0 . 9. Append the results at the end of\n",
    "bbc-performance .txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cbe2526a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB(alpha = 0.9)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"*******************************************************\\n\")\n",
    "    f.write(\"********** MULTINOMIALNB WITH 0.9 SMOOTHING ***********\\n\")\n",
    "    f.write(\"*******************************************************\\n\\n\")\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"b) confusion matrix\\n\")\n",
    "    f.write(np.array2string(conf_matrix))\n",
    "cla_report = classification_report(y_test, y_pred, target_names = data.target_names)\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"\\n\\nc) classification report\\n\")\n",
    "    f.write(cla_report)\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "macro_f1 = f1_score(y_test, y_pred, average = 'macro')\n",
    "weighted_f1 = f1_score(y_test, y_pred, average = 'weighted')\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"\\n\\nd) accuracy and f1 scores\\n\")\n",
    "    f.write(\"accuracy: \" + str(acc_score) + \"\\n\")\n",
    "    f.write(\"macro f1 score: \" + str(macro_f1) + \"\\n\")\n",
    "    f.write(\"weighted f1 score: \" + str(weighted_f1) + \"\\n\\n\")\n",
    "total = sum(distribution.values())\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"e) prior probabilities\\n\")\n",
    "    for key, value in distribution.items():\n",
    "        f.write(key + \": \" + str(value/total) + \"\\n\")\n",
    "size_of_vocabulary = td_matrix.shape[1]\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"\\nf) size of the vocabulary\\n\")\n",
    "    f.write(str(size_of_vocabulary))\n",
    "categories = {}\n",
    "for doc, category in zip(td_matrix, y):\n",
    "    if(category in categories.keys()):\n",
    "        categories[category] = categories[category] + np.sum(doc)\n",
    "    else:\n",
    "        categories[category] = np.sum(doc)\n",
    "\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"\\n\\ng) number of word-tokens in each class\\n\")\n",
    "    for key, value in categories.items():\n",
    "        f.write(data.target_names[key] + \": \" + str(value)+ \"\\n\")\n",
    "number_of_wordTokens = np.sum(td_matrix)\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"\\nh) number of word-tokens in the entire corpus\\n\")\n",
    "    f.write(str(number_of_wordTokens))\n",
    "categories = {}\n",
    "for doc, category in zip(td_matrix, y):\n",
    "    if(category in categories.keys()):\n",
    "        categories[category] = categories[category] + doc\n",
    "    else:\n",
    "        categories[category] = doc\n",
    "\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"\\n\\ni) the number and percentage of words with a frequency of zero in each class\\n\")\n",
    "    for key, value in categories.items():\n",
    "        vocabulary_with_frequency0 = size_of_vocabulary - value.count_nonzero()\n",
    "        f.write(data.target_names[key] + \": \" + str(vocabulary_with_frequency0) + \"(\" + str(vocabulary_with_frequency0/size_of_vocabulary*100) + \"%)\\n\")\n",
    "word_list = vectorizer.get_feature_names()\n",
    "count_list = np.asarray(td_matrix.sum(axis=0))[0]\n",
    "word_count_dict = dict(zip(word_list, count_list))\n",
    "words_with_frequency1 = sum(value == 1 for value in word_count_dict.values())\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"\\nj) the number and percentage of words with a frequency of one in the entire corpus\\n\")\n",
    "    f.write(\"number: \" + str(words_with_frequency1) + \"\\n\")\n",
    "    f.write(\"percentage: \" + str(words_with_frequency1/len(vectorizer.vocabulary_)*100) + \"%\\n\")\n",
    "word1 = \"hope\"\n",
    "word2 = \"peace\"\n",
    "log_prob_word1 = math.log(word_count_dict[\"hope\"]/number_of_wordTokens)\n",
    "log_prob_word2 = math.log(word_count_dict[\"peace\"]/number_of_wordTokens)\n",
    "with open(\"bbc-performance.txt\", \"a\") as f:\n",
    "    f.write(\"\\nk) your 2 favorite words (that are present in the vocabulary) and their log-prob\\n\")\n",
    "    f.write(word1 + \": \" + str(log_prob_word1) + \"\\n\")\n",
    "    f.write(word2 + \": \" + str(log_prob_word2) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d719ce35",
   "metadata": {},
   "source": [
    "&emsp;11. In a separate plain text file called bbc-discussion . txt , explain in 1 to 2 paragraphs:\n",
    "<br>(a) what metric is best suited to this dataset/task and why (see step (2))\n",
    "<br>(b) why the performance of steps (8-10) are the same or are different than those of step (7) above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4a90e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"bbc-discussion.txt\", \"w+\") as f:\n",
    "    f.write(\"a) The macro accuracy is well suited for this dataset, because the distribution of categories is relatively\\n\"+\n",
    "    \"even, and none of the categories holds a significantly heavier weight than others in the classification.\\n\\n\")\n",
    "    f.write(\"b) The steps 7, 8 and 10 yielded the same result, while step 9 yielded a slightly different result. This can\\n\"+\n",
    "    \"be explained by the fact that steps 7 and 8 are both computing on the same training set using the same algorithm without\\n\"+\n",
    "    \"inherent randomness (naive bayes). Their results are therefore the same. As for step 10, we only slightly modified the\\n\"+\n",
    "    \"smoothing value from 1.0 to 0.9, the bulk of the computation stays structurally similar and thus the result didn't change.\\n\"+\n",
    "    \"As for step 9, we changed the smoothing value significantly from 1.0 (default) to 0.001, thus introducing some slight changes\\n\"+\n",
    "    \"in the final classification.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b2689f",
   "metadata": {},
   "source": [
    "TASK TWO: DRUG CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07280c7b",
   "metadata": {},
   "source": [
    "1. Download the Drug dataset on Moodle. This dataset, in csv format, contains features that are numerical,categorical and ordinal as well as one of 5 classes to predict: DrugA, DrugB, DrugC, DrugX, or DrugY.\n",
    "2. Load the dataset in Python (you can use pandas. read_csv) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01b6b16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3aaa361f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"drug200.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831b337b",
   "metadata": {},
   "source": [
    "3. Plot the distribution of the instances in each class and store the graphic in a file called drug-distribution.pdf. You can use matplotlib. pyplot. This pre-analysis will allow you to determine if the classes are balanced, and which metric is more appropriate to use to evaluate the performance of your classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de3e5bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "drug = df.iloc[:, -1]\n",
    "distribution = Counter(drug) \n",
    "plt.bar(distribution.keys(), distribution.values())\n",
    "plt.savefig(\"drug-distribution.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b057402",
   "metadata": {},
   "source": [
    "4. Convert all ordinal and nominal features in numerical format. Make sure that your converted format respects the ordering of ordinal features, and does not introduce any ordering for nominal features. You may want to take a look at pandas .get_dummies and pandas. Categorical to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "752a4097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>BP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Na_to_K</th>\n",
       "      <th>Drug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25.355</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.093</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.114</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.798</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.043</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.567</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.006</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.894</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14.020</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.349</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Sex  BP  Cholesterol  Na_to_K  Drug\n",
       "0     23    1   2            1   25.355     4\n",
       "1     47    0   0            1   13.093     2\n",
       "2     47    0   0            1   10.114     2\n",
       "3     28    1   1            1    7.798     3\n",
       "4     61    1   0            1   18.043     4\n",
       "..   ...  ...  ..          ...      ...   ...\n",
       "195   56    1   0            1   11.567     2\n",
       "196   16    0   0            1   12.006     2\n",
       "197   52    0   1            1    9.894     3\n",
       "198   23    0   1            0   14.020     3\n",
       "199   40    1   0            0   11.349     3\n",
       "\n",
       "[200 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sex'] = pd.get_dummies(df['Sex'])\n",
    "df['BP'] = pd.Categorical(df['BP'], ordered = True, categories = ['LOW', 'NORMAL', 'HIGH'])\n",
    "df['Cholesterol'] = pd.Categorical(df['Cholesterol'], ordered = True, categories = ['NORMAL', 'HIGH'])\n",
    "df['Drug'] = pd.Categorical(df['Drug'], ordered = True, categories = ['drugA', 'drugB', 'drugC', 'drugX', 'drugY'])\n",
    "df['BP'] = df['BP'].cat.codes\n",
    "df['Cholesterol'] = df['Cholesterol'].cat.codes\n",
    "df['Drug'] = df['Drug'].cat.codes\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0588ba",
   "metadata": {},
   "source": [
    "5. Split the dataset using train_test_spli t using the default parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d8e7ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af10d0e",
   "metadata": {},
   "source": [
    "6. Run 6 different classifiers:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e335356",
   "metadata": {},
   "source": [
    "&emsp;(a) NB: a Gaussian Naive Bayes Classifier (naive_bayes. GaussianNB) with the default parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d244a86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cfb3f3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = ['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K']\n",
    "X = train.loc[:, feature_cols]\n",
    "y = train.Drug\n",
    "clf_GaussianNB = GaussianNB()\n",
    "clf_GaussianNB.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629de91c",
   "metadata": {},
   "source": [
    "&emsp;(b) Base-DT: a Decision Tree (tree.DecisionTreeClassifier) with the default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f60df6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f260ebea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'random_state': None,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_decisionTree = DecisionTreeClassifier()\n",
    "clf_decisionTree.fit(X, y)\n",
    "clf_decisionTree.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bdf774",
   "metadata": {},
   "source": [
    "&emsp;(c) Top-DT: a better performing Decision Tree found using (GridSearchCV). The gridsearch will allow you to find the best combination of hyper-parameters, as determined by the evaluation function that you have determined in step (3) above. The hyper-parameters that you will experiment with are:\n",
    "- criterion: gini or entropy\n",
    "- max_depth : 2 different values of your choice\n",
    "- min_samples_split: 3 different values of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4fe56b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "98bd3396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'criterion':['gini', 'entropy'], 'max_depth':[5, 10], 'min_samples_split':[2, 5, 10]}\n",
    "clf_topDT = GridSearchCV(DecisionTreeClassifier(), parameters)\n",
    "clf_topDT.fit(X, y)\n",
    "clf_topDT.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897cc368",
   "metadata": {},
   "source": [
    "&emsp;(d) PER: a Perceptron (linear model. Perceptron), with default parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba42a8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f989e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_perceptron = Perceptron()\n",
    "clf_perceptron.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a00a64",
   "metadata": {},
   "source": [
    "&emsp;(e) Base-MLP: a Multi-Layered Perceptron (neuraLnetwork.MLPClassifier) with 1 hidden layer of 100 neurons, sigmoid/logistic as activation function, stochastic gradient descent, and default values for the rest of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c3ca8d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "01f5fbae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', solver='sgd')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_baseMLP = MLPClassifier(hidden_layer_sizes = (100,), activation = 'logistic', solver = 'sgd')\n",
    "clf_baseMLP.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8dd9e8",
   "metadata": {},
   "source": [
    "&emsp;(f) Top-MLP: a better performing Multi-Layered Perceptron found using grid search. For this, you need\n",
    "to experiment with the following parameter values:\n",
    "- activation function: sigmoid, tanh, relu and identity\n",
    "- 2 network architectures of your choice: for eg 2 hidden layers with 30 +50 nodes, 3 hidden layers\n",
    "with 10 + 10 + 10\n",
    "- solver: Adam and stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f4054d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'activation': 'tanh', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'activation':('identity', 'logistic', 'tanh', 'relu'), 'hidden_layer_sizes':[(30, 50,), (10, 10, 10,)], 'solver':('adam', 'sgd')}\n",
    "clf_topMLP = GridSearchCV(MLPClassifier(), parameters)\n",
    "clf_topMLP.fit(X, y)\n",
    "clf_topMLP.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fec593c",
   "metadata": {},
   "source": [
    "&emsp;7. For each of the 6 classifier above, append the following information in a file called drugs-performance. txt:\n",
    "(to make it easier for the TAs, make sure that your output for each sub-question below is clearly marked\n",
    "in your output file, using the headings (a), (b) ... )<br>\n",
    "<br>(a) a clear separator (a sequence of hyphens or stars) and a string clearly describing the model (e.g. the\n",
    "model name + hyper-parameter values that you changed). In the case of Top-DT and Top-MLP,\n",
    "display the best hyperparameters found by the gridsearch.\n",
    "<br>(b) the confusion matrix\n",
    "<br>(c) the precision, recall, and F1-measure for each class\n",
    "<br>(d) the accuracy, macro-average F1 and weighted-average F1 of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "de1025ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GaussianNB\n",
    "y_test = test.Drug\n",
    "y_pred = clf_GaussianNB.predict(test.loc[:, feature_cols])\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "cla_report = classification_report(y_test, y_pred, target_names = ['drugA', 'drugB', 'drugC', 'drugX', 'drugY'])\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "macro_f1 = f1_score(y_test, y_pred, average = 'macro')\n",
    "weighted_f1 = f1_score(y_test, y_pred, average = 'weighted')\n",
    "\n",
    "with open(\"drugs-performance.txt\", \"w+\") as f:\n",
    "    f.write(\"*******************************************************\\n\")\n",
    "    f.write(\"************* GAUSSIANNB CLASSIFIER, 1 TRY ************\\n\")\n",
    "    f.write(\"*******************************************************\\n\\n\")\n",
    "    f.write(\"a) Using default hyperparameters.\\n\")\n",
    "    f.write(\"\\nb) confusion matrix\\n\")\n",
    "    f.write(np.array2string(conf_matrix) + \"\\n\")\n",
    "    f.write(\"\\nc) classification report\\n\")\n",
    "    f.write(cla_report)\n",
    "    f.write(\"\\n\\nd) accuracy and f1 scores\\n\")\n",
    "    f.write(\"accuracy: \" + str(acc_score) + \"\\n\")\n",
    "    f.write(\"macro f1 score: \" + str(macro_f1) + \"\\n\")\n",
    "    f.write(\"weighted f1 score: \" + str(weighted_f1) + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "27863e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DecisionTree\n",
    "y_test = test.Drug\n",
    "y_pred = clf_decisionTree.predict(test.loc[:, feature_cols])\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "cla_report = classification_report(y_test, y_pred, target_names = ['drugA', 'drugB', 'drugC', 'drugX', 'drugY'])\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "macro_f1 = f1_score(y_test, y_pred, average = 'macro')\n",
    "weighted_f1 = f1_score(y_test, y_pred, average = 'weighted')\n",
    "\n",
    "with open(\"drugs-performance.txt\", \"a\") as f:\n",
    "    f.write(\"*******************************************************\\n\")\n",
    "    f.write(\"*********** DECISION TREE CLASSIFIER, 1 TRY ***********\\n\")\n",
    "    f.write(\"*******************************************************\\n\\n\")\n",
    "    f.write(\"a) Using default hyperparameters.\\n\")\n",
    "    f.write(\"\\nb) confusion matrix\\n\")\n",
    "    f.write(np.array2string(conf_matrix) + \"\\n\")\n",
    "    f.write(\"\\nc) classification report\\n\")\n",
    "    f.write(cla_report)\n",
    "    f.write(\"\\n\\nd) accuracy and f1 scores\\n\")\n",
    "    f.write(\"accuracy: \" + str(acc_score) + \"\\n\")\n",
    "    f.write(\"macro f1 score: \" + str(macro_f1) + \"\\n\")\n",
    "    f.write(\"weighted f1 score: \" + str(weighted_f1) + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a9099716",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top-DT\n",
    "y_test = test.Drug\n",
    "y_pred = clf_topDT.predict(test.loc[:, feature_cols])\n",
    "hyper_params = clf_topDT.best_params_\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "cla_report = classification_report(y_test, y_pred, target_names = ['drugA', 'drugB', 'drugC', 'drugX', 'drugY'])\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "macro_f1 = f1_score(y_test, y_pred, average = 'macro')\n",
    "weighted_f1 = f1_score(y_test, y_pred, average = 'weighted')\n",
    "\n",
    "with open(\"drugs-performance.txt\", \"a\") as f:\n",
    "    f.write(\"*******************************************************\\n\")\n",
    "    f.write(\"************** TOP-DT CLASSIFIER, 1 TRY ***************\\n\")\n",
    "    f.write(\"*******************************************************\\n\\n\")\n",
    "    f.write(\"a) optimized hyperparameters: \\n\")\n",
    "    f.write(str(hyper_params))\n",
    "    f.write(\"\\n\\nb) confusion matrix\\n\")\n",
    "    f.write(np.array2string(conf_matrix) + \"\\n\")\n",
    "    f.write(\"\\nc) classification report\\n\")\n",
    "    f.write(cla_report)\n",
    "    f.write(\"\\n\\nd) accuracy and f1 scores\\n\")\n",
    "    f.write(\"accuracy: \" + str(acc_score) + \"\\n\")\n",
    "    f.write(\"macro f1 score: \" + str(macro_f1) + \"\\n\")\n",
    "    f.write(\"weighted f1 score: \" + str(weighted_f1) + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8fd8ff65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#DEFAULT PERCEPTRON\n",
    "y_test = test.Drug\n",
    "y_pred = clf_perceptron.predict(test.loc[:, feature_cols])\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "cla_report = classification_report(y_test, y_pred, target_names = ['drugA', 'drugB', 'drugC', 'drugX', 'drugY'])\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "macro_f1 = f1_score(y_test, y_pred, average = 'macro')\n",
    "weighted_f1 = f1_score(y_test, y_pred, average = 'weighted')\n",
    "\n",
    "with open(\"drugs-performance.txt\", \"a\") as f:\n",
    "    f.write(\"*******************************************************\\n\")\n",
    "    f.write(\"************ DEFAULT PER CLASSIFIER, 1 TRY ************\\n\")\n",
    "    f.write(\"*******************************************************\\n\\n\")\n",
    "    f.write(\"a) Using default hyperparameters.\\n\\n\")\n",
    "    f.write(\"\\nb) confusion matrix\\n\")\n",
    "    f.write(np.array2string(conf_matrix) + \"\\n\")\n",
    "    f.write(\"\\nc) classification report\\n\")\n",
    "    f.write(cla_report)\n",
    "    f.write(\"\\n\\nd) accuracy and f1 scores\\n\")\n",
    "    f.write(\"accuracy: \" + str(acc_score) + \"\\n\")\n",
    "    f.write(\"macro f1 score: \" + str(macro_f1) + \"\\n\")\n",
    "    f.write(\"weighted f1 score: \" + str(weighted_f1) + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7f7a6e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#BASE MLP\n",
    "y_test = test.Drug\n",
    "y_pred = clf_baseMLP.predict(test.loc[:, feature_cols])\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "cla_report = classification_report(y_test, y_pred, target_names = ['drugA', 'drugB', 'drugC', 'drugX', 'drugY'])\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "macro_f1 = f1_score(y_test, y_pred, average = 'macro')\n",
    "weighted_f1 = f1_score(y_test, y_pred, average = 'weighted')\n",
    "\n",
    "with open(\"drugs-performance.txt\", \"a\") as f:\n",
    "    f.write(\"*******************************************************\\n\")\n",
    "    f.write(\"************** BASE MLP CLASSIFIER, 1 TRY *************\\n\")\n",
    "    f.write(\"*******************************************************\\n\\n\")\n",
    "    f.write(\"a) Using default hyperparameters.\\n\\n\")\n",
    "    f.write(\"\\n\\nb) confusion matrix\\n\")\n",
    "    f.write(np.array2string(conf_matrix) + \"\\n\")\n",
    "    f.write(\"\\nc) classification report\\n\")\n",
    "    f.write(cla_report)\n",
    "    f.write(\"\\n\\nd) accuracy and f1 scores\\n\")\n",
    "    f.write(\"accuracy: \" + str(acc_score) + \"\\n\")\n",
    "    f.write(\"macro f1 score: \" + str(macro_f1) + \"\\n\")\n",
    "    f.write(\"weighted f1 score: \" + str(weighted_f1) + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e141faf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shuo_\\anaconda3_20210528\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#TOP MLP\n",
    "y_test = test.Drug\n",
    "y_pred = clf_baseMLP.predict(test.loc[:, feature_cols])\n",
    "hyper_params = clf_topMLP.best_params_\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "cla_report = classification_report(y_test, y_pred, target_names = ['drugA', 'drugB', 'drugC', 'drugX', 'drugY'])\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "macro_f1 = f1_score(y_test, y_pred, average = 'macro')\n",
    "weighted_f1 = f1_score(y_test, y_pred, average = 'weighted')\n",
    "\n",
    "with open(\"drugs-performance.txt\", \"a\") as f:\n",
    "    f.write(\"*******************************************************\\n\")\n",
    "    f.write(\"************** BASE MLP CLASSIFIER, 1 TRY *************\\n\")\n",
    "    f.write(\"*******************************************************\\n\\n\")\n",
    "    f.write(\"a) optimized hyperparameters: \\n\")\n",
    "    f.write(str(hyper_params))    \n",
    "    f.write(\"\\n\\nb) confusion matrix\\n\")\n",
    "    f.write(np.array2string(conf_matrix) + \"\\n\")\n",
    "    f.write(\"\\nc) classification report\\n\")\n",
    "    f.write(cla_report)\n",
    "    f.write(\"\\n\\nd) accuracy and f1 scores\\n\")\n",
    "    f.write(\"accuracy: \" + str(acc_score) + \"\\n\")\n",
    "    f.write(\"macro f1 score: \" + str(macro_f1) + \"\\n\")\n",
    "    f.write(\"weighted f1 score: \" + str(weighted_f1) + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4f8a77",
   "metadata": {},
   "source": [
    "&emsp;8. Redo steps 6, 10 times for each model and append the average accuracy, average macro-average F1, average\n",
    "weighted-average F1 as well as the standard deviation for the accuracy, the standard deviation\n",
    "of the macro-average F1, and the standard deviation of the weighted-average F1 at the end of the file\n",
    "drugs-performance. txt. Does the same model give you the same performance every time? Explain in a\n",
    "plain text file called drugs-discussion. txt. A 1 or 2 paragraph discussion is expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "414903d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "02d5a17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GaussianNB\n",
    "accuracy_list = []\n",
    "macro_average_list = []\n",
    "weighted_average_list = []\n",
    "y_test = test.Drug\n",
    "y_pred = clf_GaussianNB.predict(test.loc[:, feature_cols])\n",
    "for i in range(0,10):\n",
    "    accuracy_list.append(accuracy_score(y_test, y_pred))\n",
    "    macro_average_list.append(f1_score(y_test, y_pred, average = 'macro'))\n",
    "    weighted_average_list.append(f1_score(y_test, y_pred, average = 'weighted'))\n",
    "\n",
    "with open(\"drugs-performance.txt\", \"a\") as f:\n",
    "    f.write(\"*******************************************************\\n\")\n",
    "    f.write(\"*********** GAUSSIANNB CLASSIFIER, 10 TRIES ***********\\n\")\n",
    "    f.write(\"*******************************************************\\n\\n\")\n",
    "    f.write(\"average accuracy: \" + str(statistics.mean(accuracy_list)) + \"\\n\")\n",
    "    f.write(\"average macro-average F1: \" + str(statistics.mean(macro_average_list)) + \"\\n\")\n",
    "    f.write(\"average weighted-average F1: \" + str(statistics.mean(weighted_average_list)) + \"\\n\")\n",
    "    f.write(\"standard deviation for accuracy: \" + str(np.std(accuracy_list)) + \"\\n\")\n",
    "    f.write(\"standard deviation for macro-average F1: \" + str(np.std(macro_average_list)) + \"\\n\")\n",
    "    f.write(\"standard deviation for weighted-average F1: \" + str(np.std(weighted_average_list)) + \"\\n\")\n",
    "\n",
    "\n",
    "#DecisionTree\n",
    "accuracy_list = []\n",
    "macro_average_list = []\n",
    "weighted_average_list = []\n",
    "y_test = test.Drug\n",
    "y_pred = clf_decisionTree.predict(test.loc[:, feature_cols])\n",
    "for i in range(0,10):\n",
    "    accuracy_list.append(accuracy_score(y_test, y_pred))\n",
    "    macro_average_list.append(f1_score(y_test, y_pred, average = 'macro'))\n",
    "    weighted_average_list.append(f1_score(y_test, y_pred, average = 'weighted'))\n",
    "\n",
    "with open(\"drugs-performance.txt\", \"a\") as f:\n",
    "    f.write(\"*******************************************************\\n\")\n",
    "    f.write(\"*********** DECISION TREE CLASSIFIER, 10 TRIES ********\\n\")\n",
    "    f.write(\"*******************************************************\\n\\n\")\n",
    "    f.write(\"average accuracy: \" + str(statistics.mean(accuracy_list)) + \"\\n\")\n",
    "    f.write(\"average macro-average F1: \" + str(statistics.mean(macro_average_list)) + \"\\n\")\n",
    "    f.write(\"average weighted-average F1: \" + str(statistics.mean(weighted_average_list)) + \"\\n\")\n",
    "    f.write(\"standard deviation for accuracy: \" + str(np.std(accuracy_list)) + \"\\n\")\n",
    "    f.write(\"standard deviation for macro-average F1: \" + str(np.std(macro_average_list)) + \"\\n\")\n",
    "    f.write(\"standard deviation for weighted-average F1: \" + str(np.std(weighted_average_list)) + \"\\n\")\n",
    "    \n",
    "#TOP-DT\n",
    "accuracy_list = []\n",
    "macro_average_list = []\n",
    "weighted_average_list = []\n",
    "y_test = test.Drug\n",
    "y_pred = clf_topDT.predict(test.loc[:, feature_cols])\n",
    "for i in range(0,10):\n",
    "    accuracy_list.append(accuracy_score(y_test, y_pred))\n",
    "    macro_average_list.append(f1_score(y_test, y_pred, average = 'macro'))\n",
    "    weighted_average_list.append(f1_score(y_test, y_pred, average = 'weighted'))\n",
    "\n",
    "with open(\"drugs-performance.txt\", \"a\") as f:\n",
    "    f.write(\"*******************************************************\\n\")\n",
    "    f.write(\"*********** TOP-DT CLASSIFIER, 10 TRIES ***************\\n\")\n",
    "    f.write(\"*******************************************************\\n\\n\")\n",
    "    f.write(\"average accuracy: \" + str(statistics.mean(accuracy_list)) + \"\\n\")\n",
    "    f.write(\"average macro-average F1: \" + str(statistics.mean(macro_average_list)) + \"\\n\")\n",
    "    f.write(\"average weighted-average F1: \" + str(statistics.mean(weighted_average_list)) + \"\\n\")\n",
    "    f.write(\"standard deviation for accuracy: \" + str(np.std(accuracy_list)) + \"\\n\")\n",
    "    f.write(\"standard deviation for macro-average F1: \" + str(np.std(macro_average_list)) + \"\\n\")\n",
    "    f.write(\"standard deviation for weighted-average F1: \" + str(np.std(weighted_average_list)) + \"\\n\")\n",
    "    \n",
    "#DEFAULT PERCEPTRON\n",
    "accuracy_list = []\n",
    "macro_average_list = []\n",
    "weighted_average_list = []\n",
    "y_test = test.Drug\n",
    "y_pred = clf_perceptron.predict(test.loc[:, feature_cols])\n",
    "for i in range(0,10):\n",
    "    accuracy_list.append(accuracy_score(y_test, y_pred))\n",
    "    macro_average_list.append(f1_score(y_test, y_pred, average = 'macro'))\n",
    "    weighted_average_list.append(f1_score(y_test, y_pred, average = 'weighted'))\n",
    "\n",
    "with open(\"drugs-performance.txt\", \"a\") as f:\n",
    "    f.write(\"*******************************************************\\n\")\n",
    "    f.write(\"******* DEFAULT PERCEPTRON CLASSIFIER, 10 TRIES *******\\n\")\n",
    "    f.write(\"*******************************************************\\n\\n\")\n",
    "    f.write(\"average accuracy: \" + str(statistics.mean(accuracy_list)) + \"\\n\")\n",
    "    f.write(\"average macro-average F1: \" + str(statistics.mean(macro_average_list)) + \"\\n\")\n",
    "    f.write(\"average weighted-average F1: \" + str(statistics.mean(weighted_average_list)) + \"\\n\")\n",
    "    f.write(\"standard deviation for accuracy: \" + str(np.std(accuracy_list)) + \"\\n\")\n",
    "    f.write(\"standard deviation for macro-average F1: \" + str(np.std(macro_average_list)) + \"\\n\")\n",
    "    f.write(\"standard deviation for weighted-average F1: \" + str(np.std(weighted_average_list)) + \"\\n\")\n",
    "    \n",
    "#BASE MLP\n",
    "accuracy_list = []\n",
    "macro_average_list = []\n",
    "weighted_average_list = []\n",
    "y_test = test.Drug\n",
    "y_pred = clf_baseMLP.predict(test.loc[:, feature_cols])\n",
    "for i in range(0,10):\n",
    "    accuracy_list.append(accuracy_score(y_test, y_pred))\n",
    "    macro_average_list.append(f1_score(y_test, y_pred, average = 'macro'))\n",
    "    weighted_average_list.append(f1_score(y_test, y_pred, average = 'weighted'))\n",
    "\n",
    "with open(\"drugs-performance.txt\", \"a\") as f:\n",
    "    f.write(\"*******************************************************\\n\")\n",
    "    f.write(\"***************** BASE MLP CLASSIFIER, 10 TRIES *******\\n\")\n",
    "    f.write(\"*******************************************************\\n\\n\")\n",
    "    f.write(\"average accuracy: \" + str(statistics.mean(accuracy_list)) + \"\\n\")\n",
    "    f.write(\"average macro-average F1: \" + str(statistics.mean(macro_average_list)) + \"\\n\")\n",
    "    f.write(\"average weighted-average F1: \" + str(statistics.mean(weighted_average_list)) + \"\\n\")\n",
    "    f.write(\"standard deviation for accuracy: \" + str(np.std(accuracy_list)) + \"\\n\")\n",
    "    f.write(\"standard deviation for macro-average F1: \" + str(np.std(macro_average_list)) + \"\\n\")\n",
    "    f.write(\"standard deviation for weighted-average F1: \" + str(np.std(weighted_average_list)) + \"\\n\")\n",
    "    \n",
    "    \n",
    "#TOP MLP\n",
    "accuracy_list = []\n",
    "macro_average_list = []\n",
    "weighted_average_list = []\n",
    "y_test = test.Drug\n",
    "y_pred = clf_topMLP.predict(test.loc[:, feature_cols])\n",
    "for i in range(0,10):\n",
    "    accuracy_list.append(accuracy_score(y_test, y_pred))\n",
    "    macro_average_list.append(f1_score(y_test, y_pred, average = 'macro'))\n",
    "    weighted_average_list.append(f1_score(y_test, y_pred, average = 'weighted'))\n",
    "\n",
    "with open(\"drugs-performance.txt\", \"a\") as f:\n",
    "    f.write(\"*******************************************************\\n\")\n",
    "    f.write(\"***************** TOP MLP CLASSIFIER, 10 TRIES ********\\n\")\n",
    "    f.write(\"*******************************************************\\n\\n\")\n",
    "    f.write(\"average accuracy: \" + str(statistics.mean(accuracy_list)) + \"\\n\")\n",
    "    f.write(\"average macro-average F1: \" + str(statistics.mean(macro_average_list)) + \"\\n\")\n",
    "    f.write(\"average weighted-average F1: \" + str(statistics.mean(weighted_average_list)) + \"\\n\")\n",
    "    f.write(\"standard deviation for accuracy: \" + str(np.std(accuracy_list)) + \"\\n\")\n",
    "    f.write(\"standard deviation for macro-average F1: \" + str(np.std(macro_average_list)) + \"\\n\")\n",
    "    f.write(\"standard deviation for weighted-average F1: \" + str(np.std(weighted_average_list)) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "89a9bb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"drugs-discussion.txt\", \"w+\") as f:\n",
    "    f.write(\"Since the standard deviation of all the models are 0 (or erroneously close to 0 due to limitation of digital\\n\"+\n",
    "           \"circuits and bits), the prediction of each model is fixed given a fixed training input. However, there are still\\n\"+\n",
    "           \"2 questions in my mind: 1. why is it that my TOP models obtained from cross-validation not seem to improve on the\\n\"+\n",
    "           \"prediction results; 2: the perceptrons are horrendously inaccurate. Is it because the data set is too small?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3216b387",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
